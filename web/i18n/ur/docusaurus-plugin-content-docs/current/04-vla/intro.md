---
sidebar_position: 1
---

# ماڈیول 4: Vision-Language-Action (VLA) Models

## تعارف

ماڈیول 4 میں خوش آمدید، Physical AI کا جدید ترین حصہ! Vision-Language-Action ماڈلز کے بارے میں سیکھیں جو روبوٹ کو سمجھنے، سوچنے، اور عمل کرنے کے قابل بناتے ہیں۔

## آپ کیا سیکھیں گے

اس ماڈیول میں، آپ:
- multimodal AI سسٹمز (vision + language + action) کو سمجھیں گے
- سیکھیں گے کہ روبوٹ بصری معلومات کو کیسے محسوس اور interpret کرتے ہیں
- زبان پر مبنی روبوٹ کنٹرول کو دریافت کریں گے
- perception، reasoning، اور جسمانی actions کو یکجا کریں گے

## پیشگی ضروریات

- ماڈیول 1، 2، اور 3 کی تکمیل
- مضبوط Python پروگرامنگ مہارتیں
- neural networks اور computer vision کی بنیادی باتوں کی سمجھ

## شروع کریں

VLA ماڈلز روبوٹکس کے مستقبل کی نمائندگی کرتے ہیں - سسٹمز جو دیکھ سکتے ہیں، زبان کو سمجھ سکتے ہیں، اور جسمانی کام انجام دے سکتے ہیں۔ آئیے اس دلچسپ سرحد کو دریافت کریں!

[پہلے سبق پر جاری رکھیں →](#)
