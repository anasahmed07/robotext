---
title: Conversational Robotics (Urdu)
sidebar_label: Conversational Robotics
description: Vision-Language-Action (VLA) models bridging LLMs and Robotics.
keywords: [VLA, LLM, Vision-Language-Action, OpenAI Whisper, GPT-4o]
---

# بات چیت کرنے والی روبوٹکس (VLA)

فزیکل AI کی آخری حد بڑے لینگویج ماڈلز (LLMs) کا روبوٹک کنٹرول کے ساتھ انضمام ہے۔ ہم اسے **Vision-Language-Action (VLA)** کہتے ہیں۔ یہ ہمیں روبوٹ سے سادہ انگریزی (یا اردو) میں بات کرنے کی اجازت دیتا ہے۔

## VLA فن تعمیر

ایک VLA سسٹم قدرتی زبان کو ROS 2 کے اعمال (actions) میں ترجمہ کرتا ہے۔

![Schematic of VLA Architecture: Voice Input -> Whisper (Text) -> LLM (Planner) -> ROS 2 Action Server -> Robot. Style: NotebookLM dark mode schematic.](/img/docs/04/vla-architecture.png)

1. **صارف**: "سرخ سیب اٹھاؤ۔"
2. **ASR (Whisper)**: آڈیو کو ٹیکسٹ میں تبدیل کرتا ہے۔
3. **VLM (GPT-4o/Gemini)**: منظر کی تصویر کا تجزیہ کرتا ہے، سیب کو ڈھونڈتا ہے، اور پکڑنے (grasp) کی منصوبہ بندی کرتا ہے۔
4. **روبوٹ**: منصوبے پر عمل کرتا ہے۔

## LLM سے ROS 2 پل (Bridge)

یہاں ایک تصوراتی مثال ہے کہ LLM کس طرح ROS 2 کمانڈز تیار کر سکتا ہے۔

```python title="llm_bridge.py"
import openai
import rclpy
from std_msgs.msg import String

def get_action_from_llm(user_prompt):
    # System prompt defines the available robot actions
    system_prompt = """
    You are a robot controller. Output ONLY a JSON command.
    Available actions:
    - move_forward(meters)
    - turn(degrees)
    - say(text)
    """
    
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content

def main():
    rclpy.init()
    node = rclpy.create_node('llm_bridge')
    pub = node.create_publisher(String, 'robot_commands', 10)
    
    command = "Walk forward 2 meters and say hello"
    json_action = get_action_from_llm(command)
    
    msg = String()
    msg.data = json_action
    pub.publish(msg)
    
    print(f"Sent command: {json_action}")
    # Output: {"actions": [{"cmd": "move_forward", "arg": 2}, {"cmd": "say", "arg": "hello"}]}

if __name__ == "__main__":
    main()
```

:::info مستقبل
ہم روبوٹس کو "پروگرامنگ" کرنے سے "سکھانے" کی طرف بڑھ رہے ہیں۔ VLA ماڈلز روبوٹس کو مظاہرے اور قدرتی زبان کی ہدایات سے سیکھنے کے قابل بناتے ہیں۔
:::
